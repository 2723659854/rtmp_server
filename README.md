##  rtmp_server

### 简介
 一个使用纯php开发的rtmp直播服务器，支持rtmp协议推流，rtmp拉流，支持flv格式拉流，可以使用http或者ws协议拉流。<br>

### 安装
```bash 
composer create-project xiaosongshu/rtmp_server
```

### 环境配置
本项目使用php8.1，建议新手使用<a href = "https://www.xp.cn/">phpstudy</a>这个集成环境，一键搞定环境搭建工作。<br>
或者使用本项目提供的<a href = "https://www.docker.com/">docker</a>环境，在本项目根目录下命令行执行以下命令：
```bash 
docker-compose up -d
```
本项目自带的docker配置已经集成了php相关扩展和ffmpeg。<br>
本项目默认使用三个端口：
```text
1935:rtmp服务
8501:flv服务
80:web服务
```
### 开启服务
进入本项目的根目录，在命令行执行以下命令：
```bash 
php server.php
```
### 关闭服务
windows系统 
```bash 
ctrl + c 
```
linux系统
```bash 
kill -9 pid
```
### 推流

```txt 
推流地址：rtmp://127.0.0.1/a/b

其中a是应用名称，b是频道名称，这两个参数可以改变，但只能是英文或者数字。可以自行修改。
```
我自己调试使用的OBS，使用方法可以参考
<a href="https://www.tencentcloud.com/zh/document/product/267/31569">网上教程</a>，
OBS工具<a href ="https://obsproject.com/">下载</a>。<br>
你也可以使用<a href="https://ffmpeg.org/">ffmpeg</a>工具，命令如下
```bash 
ffmpeg -re -stream_loop 1  -i "movie.mp4" -vcodec h264 -acodec aac -f flv rtmp://127.0.0.1/a/b
```
命令详解
```text
-re：表示以实时模式运行 FFMpeg。
-stream_loop 1：设置流循环次数为1。
-i "movie.mp4"：指定输入文件为"movie.mp4"。
-vcodec h264：强制使用 H.264 视频编解码器进行编码。
-acodec aac：强制使用 AAC 音频编解码器进行编码。
-f flv：指定输出格式为 FLV。
rtmp://127.0.0.1/a/b：指定 RTMP 服务器的地址和路径。
```

### 拉流
```text
rtmp: rtmp://127.0.0.1/a/b

flv(http): http://127.0.0.1:8501/a/b.flv

flv(ws): ws://127.0.0.1:8501/a/b.flv

hls：http://127.0.0.1:80/a/b.m3u8 （需要使用ffmpeg转换协议）
```
播放工具可以使用:<br>
<a href="https://get.videolan.org/vlc/3.0.20/win64/vlc-3.0.20-win64.exe">VLC</a>打开网络串流地址<br>
<a href="https://ffmpeg.org/">ffplay</a> ``` ffplay rtmp://127.0.0.1/a/b ```<br>
本项目提供网页播放，直接使用浏览器打开index.html即可<a href="http://127.0.0.1:80/index.html">播放flv</a>。<br>
本项目提供网页播放，直接使用浏览器打开play.html即可<a href="http://127.0.0.1:80/play.html">播放hls</a>。<br>

### 延迟问题

在理想状态的情况下测试，延迟在1秒以内。理想状态就是：直播服务器和推流，拉流都在同一台电脑，减少了网络波动的影响。<br>
另外，如果使用浏览器播放，某些浏览器如果切换到后台，因为节能的关系，浏览器不会播放直播，当浏览器切换到前台才会接着上一次的位置重新播放，这样子延迟
就相当高了。<br>
当然了如果服务端处理器性能拉胯，延迟也会很高，因为直播服务很耗性能的。

### 关于对hls协议的支持

本项目非常抱歉没有实现对hls的支持，但是提供了一个解决办法，使用ffmpeg工具对协议的转换，以上面的`rtmp://127.0.0.1/a/b`流为例，本项目默认将
hls协议的文件保存在hls目录下，所以你需要在项目根目录手动创建一个/a/目录。然后在命令行执行以下命令即可完成rtmp协议转换为hls协议。
```bash 
ffmpeg -i rtmp://127.0.0.1/a/b -c:v h264 -c:a aac -f hls -hls_time 3 -hls_list_size 0   ./a/b.m3u8
```
若需要退出协议转换，请在命令行输入`q`即可退出。
```ps
注意：如果需要使用hls协议，那么创建流的时候，应用名称（比如上面的变量a）要避免使用本项目的目录，否则会污染项目。需要避开的关键字如下所示：
MediaServer,public,Root,SabreAMF,vendor。另外不建议使用php语言相关关键字，可能后期拓展会用到。
```

命令详解

```text
-i rtmp://127.0.0.1/a/b              rtmp输入流，即rtmp拉流地址                     可以修改
-c:v h264                            选择视频编码方式为h264                         不用修改
-c:a aac                             选择音频编码方式为aac                          不用修改
-f hls                               指定输出格式为hls                             不用修改
-hls_time 3                          设置hls切片的时间间隔为1秒                      可以修改
-hls_list_size 0                     设置hls播放列表的大小为0，即只生成一个播放列表文件  不用修改
./a/b.m3u8                           指定输出文件的路径和名称                        可以修改
```
####  关于延迟的讨论
hls协议兼容性很好，可以支持Android，iOS，Linux，Windows平台,可以用来作为点播和直播的媒体源。hls的工作原理：对媒体资源进行切片，就是将一个比较
大的视频分割成很多小的文件，然后创建一个索引文件，索引文件记录了每一个切片文件的顺序和时间。客户端在播放的时候，首先获取索引文件，比如上面的
./a/b.m3u8,客户端读取这个索引文件的内容，按顺序请求上面列出的切片文件，逐个按顺序播放。这里你可以看出来，hls在作为点播资源的时候，将大文件分割成小文件，可以
一边下载一边播放，减轻了网络请求的压力。但是当作为直播资源的时候，需要对媒体资源生成切片，生成切片需要消耗时间，比如上面设置的切片时间3秒，那么在
直播的时候，仅仅切片就会产生3秒延迟，然后数据从推流设备经过网络发送到服务器，然后服务器经过网络转发给播放客户端，这条线路经过多少网络设备，每一层
都会产生延迟，最后叠加的延迟很可怕。我在本地测试，切片设置的1秒，但是产生的延迟最低是25秒，这已经是比较理想的情况了。而且这个延迟会随着直播时间增加
而逐渐增加，因为作为直播流的时候，服务端会不停的切片并更新索引文件，那么客户端也会不停的请求索引文件，然后读取索引文件后再请求切片文件，客户端每
播放一个切片文件，就会产生两次请求，这个请求耗费的时间会逐渐累计，导致延迟越来越高，越来越离谱，可以高达15分钟。所以直播抛弃这个方案。<br>

对于实时性要求不高的场景，可以使用hls协议。但是如果实时性要求很高，不要使用，比如在线教学，用户要抓狂的。<br>

rtmp协议几乎绝大部分浏览器是不支持，所以无法使用，只有部分播放器支持。这里不得不说ffmpeg了，相当牛逼。市面上大多数的播放器都是使用ffmpeg的插件开发
的，有些播放器更是直接给ffmpeg套一个壳。使用rtmp协议拉流，延迟我这里本地测试可以达到1秒，这个对于聊天，开会，授课，直播这些场景是够用了，用户对延迟
基本上是无感知的。rtmp协议主要用来推流，用于拉流比较少。但是网上还是有大佬自己开发客户端播放器，使用rtmp拉流。比如使用上面提到的ffmpeg插件封装。<br>

然后就是flv作为客户端拉流的时候，这个延迟我本地测试在1-3秒之间。以前flv浏览器都是支持的，后来因为安全问题，浏览器厂商移除了对flv的支持。但是我们
浏览器可以使用javascript来支持，推荐一下<a href="https://github.com/bilibili/flv.js">flv.js</a>。这个js是bilibili的``谦谦``开发的，
高中学历，自学编程，相当牛逼了，这个js应用相当广泛(感觉社会就是极少数天才在引领社会的进步)。当然，Windows，Linux，Android，iOS也是支持flv格式
的媒体资源的，但是iOS的浏览器模式只支持自家的hls，不能播放flv，这个时候就要使用flv.js来播放了，你可以将flv.js嵌入的播放器，或者使用第三方的播放
插件，市面上是很多的。所以，在直播这种对实时性要求很高的场景，建议使用flv作为媒体资源。<br>

现在为了实现浏览器端的推流，出现了webrtc，这个协议是实现端对端的推流。这个协议和rtmp的区别是：rtmp使用的tcp协议，需要三次握手，需要对包的完整性
进行校验；而webrtc是使用的udp协议，不需要握手，不需要校验，所以webrtc推流速度更快。webrtc协议是浏览器和浏览器之间的直接建立信道通信，只是在建立
链接的时候，需要通过服务器获取对端地址，当建立好链接之后，浏览器之间直接通信，不再经过服务器，这个时候把服务器关闭，也不影响通信。所以webrtc用在视频
电话，会议比较多，可以参考我的另外一个项目<a href="https://github.com/2723659854/webrtc">一对一聊天</a>。但是正因为这是端对端通信，如果用
在直播场景，那么所有的观众客户端都会和主播的浏览器建立通信，主播的宽带是不够的，如果主播的电脑配置不高，对cpu也是考验。<br>

所以当前市面上的直播，为了提升用户观看体验，减少延迟。有很多种方案，下面简单概括一下。<br>

比如优化推客户端的编码方法，优化拉流客户端的解码方法。在推流客户端，目前已经有很多成熟的方法对视频和音频数据进行压缩，对B帧
和P帧的处理，尽可能减小传输数据的大小且不影响用户观看质量。对应的，拉流客户端优化解码方法对更小的数据包进行还原数据。不过这个对设备的性能也是一个考验，
因为计算量更大，耗能更高。但是单位时间内，传输的有效的数据更多了，效率更高了。<br>

然后就是对传输网路进行优化，因为是直播场景，在IP层可能会禁用Nagle算法(就是有数据直接发送，不等待一定时间发送或者不等待足够长度数据再发送)，
但是这个可能会导致网络拥堵，要看怎么取舍了。另外，就是尽量减少网络层级，减少转发。狠狠地加宽带，就不会高延迟了。<br>

现在已经有了针对直播的CDN服务了，实现原理就是推流客户端将数据推送到主服务器上，然后用几台从服务器也作为直播服务器，不过拉流是从主服务器上拉流，而
普通用户拉流是在从服务器上拉流。这是基本原理，实际应用会复杂一些，比较大型的直播，可能会在每个地区设置从服务器。<br>

还有就是上面提到的webrtc协议，优点就是传输速度更快。所以推流的时候就是用webrtc协议将数据推送到服务器，拉流使用rtmp或者flv。这样子就减少了推流
的延迟，需要服务端对协议的转换。原理就是把服务端当做一个浏览器客户端，拉去推流客户端的数据，然后将数据格式转化为rtmp。<br>

以上观点仅代表个人，如有冒犯，可联系修正。

### 其他

 需要注意的是，本项目使用的是php的cli模式，和传统的fpm模式有根本的区别。
 如果在运行的时候报错，请检查报错信息，多半是缺少php扩展，根据报错信息安装对应扩展，如果使用本项目的docker配置，一般不会报错的。<br>
 本项目已经添加了自定义的hls协议，在`Root\HLSDemo::class`，开启hls协议在`MediaServer::publisherOnFrame()`方法里面。不过本协议尚且有问题。有兴趣的
 朋友可以帮忙修正一下。

### 声明

本项目只用于学习，里面很多资料来源于网络，如有侵权，请联系删除。本项目完全开源，用于相互学习交流，如有问题，欢迎联系我。

### 联系我
```txt
email: 2723659854@qq.com  171892716@qq.com
```




 

 
 

 
 
 
 